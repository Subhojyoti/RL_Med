$T$ denotes the time horizon. We use capitalized calligraphic notations to denote sets while individual elements within the set is denoted by non-capitalized alphabets. $\A$ denotes the finite set of actions  with individual action indexed by $a$ such that $a=1,\ldots, K$. We assume that the total number of actions is discrete and constant throughout the time horizon and $|\A|=K$. In the gridworld setting $K=4$. We define an MDP $M$ with the tuple $M  = (\S,\A,P,d_R, d_0,\gamma)$ where $\S$ is the set of states, $\A$ is the set of actions, $P$ is the transition function, $d_R$ is the reward distribution over the states indicating how the rewards are generated, $d_0$ is the initial state distribution and $\gamma$ is the discounting factor.